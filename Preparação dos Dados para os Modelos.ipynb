{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9cc49c83",
   "metadata": {},
   "source": [
    "#ANÁLISE DE SENTIMENTO EM REVIEWS DE TRÊS ESTRELAS: UMA PROPOSTA DE CLASSIFICAÇÃO MULTIRRÓTULO\n",
    "\n",
    "# Seção 7. Preparação dos Dados para os Modelos de Aprendizado de Máquina"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a2af43",
   "metadata": {},
   "source": [
    "#### Importação das Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "817da835",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\carolina.gadelha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Download and installation successful\n",
      "You can now load the package via spacy.load('pt_core_news_sm')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "import numpy as np\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "import spacy\n",
    "import spacy.cli\n",
    "spacy.cli.download(\"pt_core_news_sm\")\n",
    "import pt_core_news_sm\n",
    "spc_pt = pt_core_news_sm.load()\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, multilabel_confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f36f0f39",
   "metadata": {},
   "source": [
    "#### Task 0: Carregar o dataset B2W-Reviews01-Anotado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef5041f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Carrega o dataset anotado\n",
    "data = pd.read_csv('b2w-reviews-01-anotado.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a15c8ec",
   "metadata": {},
   "source": [
    "#### Task 01: Eliminar Reviews Neutras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e2d5fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_anotado = data_anotado[data_anotado['anotacao'] != 'neutro']\n",
    "data_anotado.reset_index(drop=True, inplace=True)\n",
    "data_anotado.index.name = 'index'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6797d77a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "positivo  negativo    2971\n",
       "positivo              1283\n",
       "negativo               525\n",
       "Name: anotacao, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.anotacao.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f7fc15",
   "metadata": {},
   "source": [
    "#### Task 02: Preparação dos Dados para Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9bf02ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pré-processamento dos textos da coluna Reviews \n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stopwords_pt = stopwords.words(\"portuguese\")\n",
    "stopwords_pt = [i for i in stopwords_pt if i not in [\"não\", \"nenhum\", \"nada\", \"jamais\", \"nunca\", \"nem\"]]\n",
    "\n",
    "def limpa_texto(texto):\n",
    "    texto = texto.lower() #Transforma texto em minúsculo\n",
    "    texto = re.sub(r\"[\\W\\d_]+\", \" \", texto) #Filtra apenas letras\n",
    "    texto = [pal for pal in texto.split() if pal not in stopwords_pt] #Remove stopwords\n",
    "    spc_texto = spc_pt(\" \".join(texto))\n",
    "    tokens = [word.lemma_ if word.lemma_ != \"-PRON-\" else word.lower_ for word in spc_texto] #Lemmatiza\n",
    "\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "#Aplica função na coluna Review\n",
    "data_anotado['review'] = data_anotado['review'].apply(limpa_texto)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e4ea565",
   "metadata": {},
   "source": [
    "#### Task 03: Transformar classes de sentimento em colunas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933bf61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lista as classes de sentimento existentes no dataset\n",
    "SENTIMENTOS = ['positivo','negativo']\n",
    " \n",
    "#Transforma as classes em coluna com valores preenchidos \n",
    "for sentimento in SENTIMENTOS[::-1]:\n",
    "    data_anotado.insert(1,sentimento,data_anotado.anotacao.apply(lambda x: 1 if sentimento in x else 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e80879bd",
   "metadata": {},
   "source": [
    "#### Task 04: Dividir os dados em Treino e Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad52258e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Divide o Dataset em Treino e Teste\n",
    "X = data_anotado[\"review\"]\n",
    "y = data_anotado[['positivo', 'negativo']]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df50bfc1",
   "metadata": {},
   "source": [
    "#### Task 05: Vetorizar os textos da coluna Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668a0b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vetoriza as Reviews com TFIDF\n",
    "vectorizer_tfidf = TfidfVectorizer(max_features=5000)\n",
    "vectorizer_tfidf.fit(X)\n",
    "X_train_tfidf = vectorizer_tfidf.transform(X_train)\n",
    "X_test_tfidf = vectorizer_tfidf.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012416b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vetoriza as Reviews com BOW\n",
    "vectorizer_bow = CountVectorizer(binary=True)\n",
    "vectorizer_bow.fit(X)\n",
    "X_train_bow = vectorizer_bow.transform(X_train)\n",
    "X_test_bow = vectorizer_bow.transform(X_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
